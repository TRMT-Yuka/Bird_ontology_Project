{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ内に存在しない親を探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以降不足した親を繰り返し探す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "# with open(\"data_extract/ontology_path.pickle\", 'rb') as f:\n",
    "# with open(\"data_extract/ontology_path_v2.pickle\", 'rb') as f:\n",
    "# with open(\"data_extract/ontology_path_v3.pickle\", 'rb') as f:\n",
    "# with open(\"data_extract/ontology_path_v4.pickle\", 'rb') as f:\n",
    "# with open(\"data_extract/ontology_path_v5.pickle\", 'rb') as f:\n",
    "with open(\"data_extract/ontology_path_v6.pickle\", 'rb') as f:\n",
    "    data_origin = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47336"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_origin[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_id = set()\n",
    "all_p_taxon = set()\n",
    "for d in data_origin:\n",
    "    all_id.add(d[\"id\"])\n",
    "    all_p_taxon.add(d[\"parent_taxon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9939"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_p_taxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_p_taxon = all_p_taxon-all_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(absent_p_taxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{None, 'Q160830', 'Q2043179'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absent_p_taxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存在しない親を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('sh3_absent_p_taxon.sh', 'w', encoding='UTF-8') as f:\n",
    "# with open('sh4_absent_p_taxon.sh', 'w', encoding='UTF-8') as f:\n",
    "# with open('sh5_absent_p_taxon.sh', 'w', encoding='UTF-8') as f:\n",
    "with open('sh6_absent_p_taxon.sh', 'w', encoding='UTF-8') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    \n",
    "    for item in absent_p_taxon:\n",
    "        i = str(item)\n",
    "#         command = \"curl -sLH 'Accept: application/json' http://www.wikidata.org/entity/\"+i+\" | jq . > data_json_10/\"+i+\".json\"\n",
    "        command = \"curl -sLH 'Accept: application/json' http://www.wikidata.org/entity/\"+i+\" | jq . > data_json_13/\"+i+\".json\"\n",
    "        f.write(command+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data_json_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "parse error: Invalid numeric literal at line 1, column 10\n"
     ]
    }
   ],
   "source": [
    "# !bash sh3_absent_p_taxon.sh\n",
    "# !bash sh4_absent_p_taxon.sh\n",
    "# !bash sh5_absent_p_taxon.sh #None.jsonができてしまったので，それは削除\n",
    "!bash sh6_absent_p_taxon.sh #None.jsonができてしまったので，それは削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以降はこれまでと同じ流れでdictに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prog1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def logmaker(file_dir,file,error):\n",
    "    with open(file_dir+\"/\"+file+\"_log.txt\", 'w',encoding=\"utf-8\") as log_f:\n",
    "        log_f.write(error+\"\\n\")\n",
    "\n",
    "def Make_jsonpikle(file_dir):\n",
    "    files = os.listdir(file_dir)\n",
    "    files_1 = [file.replace(\".json\",\"\") for file in files]\n",
    "    all_bird_dict = []\n",
    "\n",
    "    for i in range(len(files_1)):\n",
    "        file = files_1[i]\n",
    "        print('\\r%d / %d' %(i, len(files_1)), end='')\n",
    "\n",
    "        try:\n",
    "            with open(file_dir+'/'+file+\".json\", 'r',encoding=\"utf-8\") as rf:\n",
    "                json_dict = json.load(rf)\n",
    "        except:\n",
    "            logmaker(file_dir,file,\"read json\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        bird_dict = {}\n",
    "        url = \"https://www.wikidata.org/wiki/\"+file\n",
    "        bird_dict[\"id\"] = file\n",
    "        \n",
    "        try:\n",
    "            bird_dict[\"en_name\"] = json_dict['entities'][file][\"labels\"][\"en\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"en_name\"] = None\n",
    "            logmaker(file_dir,file,\"en_name\")\n",
    "        try:\n",
    "            bird_dict[\"ja_name\"] = json_dict['entities'][file][\"labels\"][\"ja\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"ja_name\"] = None\n",
    "\n",
    "        \n",
    "        bird_dict[\"en_aliases\"] = {}\n",
    "        cnt1 = 0\n",
    "        try:\n",
    "            for d in json_dict['entities'][file][\"aliases\"][\"en\"]:\n",
    "                bird_dict[\"en_aliases\"][cnt1] = d[\"value\"]\n",
    "                cnt1 = cnt1 + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        bird_dict[\"ja_aliases\"] = {}\n",
    "        cnt2 = 0\n",
    "        try:\n",
    "            for d in json_dict['entities'][file][\"aliases\"][\"ja\"]:\n",
    "                bird_dict[\"ja_aliases\"][cnt2]=d[\"value\"]\n",
    "                cnt2 = cnt2 + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        bird_dict[\"img_urls\"] = {}\n",
    "        cnt3 = 0\n",
    "        try:\n",
    "            for img in json_dict['entities'][file][\"claims\"][\"P18\"]:\n",
    "                img_url = url+\"#/media/File:\"+img[\"mainsnak\"][\"datavalue\"][\"value\"].replace(\" \",\"%20\")\n",
    "                bird_dict[\"img_urls\"][cnt3]=img_url\n",
    "                cnt3 = cnt3 + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"taxon_rank\"] = json_dict['entities'][file][\"claims\"][\"P105\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "        except:\n",
    "            bird_dict[\"taxon_rank\"] = None\n",
    "            logmaker(file_dir,file,\"taxon_rank\")\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"taxon_name\"] = json_dict['entities'][file][\"claims\"][\"P225\"][0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"taxon_name\"] = None\n",
    "            logmaker(file_dir,file,\"taxon_name\")\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"parent_taxon\"] = json_dict['entities'][file][\"claims\"][\"P171\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "        except:\n",
    "            bird_dict[\"parent_taxon\"] = None\n",
    "            logmaker(file_dir,file,\"parent_taxon\")\n",
    "        all_bird_dict.append(bird_dict)\n",
    "\n",
    "\n",
    "    with open(\"data_extract/\"+file_dir+\".pickle\", 'wb') as bf:\n",
    "        pickle.dump(all_bird_dict,bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [10]:\n",
    "# for i in [11]:\n",
    "# for i in [12]:\n",
    "# for i in [13]:\n",
    "#     Make_jsonpikle(\"data_json_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data_extract/data_json_10.pickle\",\"rb\") as f:\n",
    "# with open(\"data_extract/data_json_11.pickle\",\"rb\") as f:\n",
    "# with open(\"data_extract/data_json_12.pickle\",\"rb\") as f:\n",
    "with open(\"data_extract/data_json_13.pickle\",\"rb\") as f:\n",
    "    data_add = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_add+data_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47338"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d = {}\n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d\n",
    "    \n",
    "ID_list = []\n",
    "for v in data:\n",
    "    ID_list.append(v[\"taxon_rank\"])\n",
    "    ID_list.append(v[\"parent_taxon\"])\n",
    "ID_set = set(ID_list)\n",
    "\n",
    "ID_d = dict()\n",
    "nodata_set = set()\n",
    "for k in ID_set:\n",
    "    if k in data_d:\n",
    "        ID_d[k] = data_d[k][\"en_name\"]\n",
    "    else:\n",
    "        nodata_set.add(k)\n",
    "\n",
    "ID_d_ja = dict()\n",
    "nodata_set_ja = set()\n",
    "for k in ID_set:\n",
    "    if k in data_d:\n",
    "        ID_d_ja[k] = data_d[k][\"ja_name\"]\n",
    "    else:\n",
    "        nodata_set_ja.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_data = []\n",
    "for d in data:\n",
    "    try:\n",
    "        d[\"taxon_rank_name\"] = ID_d[d[\"taxon_rank\"]]\n",
    "        d[\"taxon_rank_ja_name\"] = ID_d_ja[d[\"taxon_rank\"]]\n",
    "\n",
    "        d[\"parent_taxon_name\"] = ID_d[d[\"parent_taxon\"]]\n",
    "        d[\"parent_taxon_ja_name\"] = ID_d_ja[d[\"parent_taxon\"]]\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"en_aliases\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \",\" +v\n",
    "        d[\"en_aliases\"] = s\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"ja_aliases\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \",\" +v\n",
    "        d[\"ja_aliases\"] = s\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"img_urls\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \" \" +v\n",
    "        d[\"img_urls\"] = s\n",
    "    except:\n",
    "        non_data.append(d[\"taxon_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree import Node, RenderTree\n",
    "node_set = set()\n",
    "\n",
    "for d in data:\n",
    "    _id = d[\"id\"].replace(\"]\",\"\")\n",
    "    if type(d[\"parent_taxon\"]) == str:\n",
    "        _parent = d[\"parent_taxon\"].replace(\"]\",\"\")\n",
    "    \n",
    "    if d[\"parent_taxon\"] in node_set:\n",
    "        exec('%s = Node(d[\"id\"],parent= %s)' % (_id,_parent))\n",
    "        node_set.add(d[\"id\"])\n",
    "    elif d[\"parent_taxon\"] != None:\n",
    "        exec('%s = Node(d[\"parent_taxon\"])' % (_parent))\n",
    "        node_set.add(d[\"parent_taxon\"])\n",
    "        exec('%s = Node(d[\"id\"],parent= %s)' % (_id,_parent))\n",
    "        node_set.add(d[\"id\"])\n",
    "    else:\n",
    "        exec('%s = Node(d[\"id\"],parent= None)' % (_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    _id = d[\"id\"].replace(\"]\",\"\")\n",
    "    exec('d[\"path\"] = str(%s).replace(\"Node(\",\"\").replace(\")\",\"\")' % (_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "for d in data:\n",
    "    dict_data[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    try:\n",
    "#         print(d)\n",
    "        path_list = d[\"path\"].replace(\"'/\",\"\").replace(\"'\",\"\").split(\"/\")\n",
    "        path_list\n",
    "\n",
    "        ja_path_name = []\n",
    "        en_path_name = []\n",
    "        path_taxon_rank_name = []\n",
    "\n",
    "        for path in path_list:\n",
    "            if path in dict_data:\n",
    "                if dict_data[path][\"ja_name\"] != \"\" and type(dict_data[path][\"ja_name\"])==str:\n",
    "                    ja_path_name.append(dict_data[path][\"ja_name\"])\n",
    "                    en_path_name.append(dict_data[path][\"en_name\"])\n",
    "                else:\n",
    "                    ja_path_name.append(dict_data[path][\"en_name\"])\n",
    "                    en_path_name.append(dict_data[path][\"en_name\"])\n",
    "                if dict_data[path][\"taxon_rank_name\"] != \"\" and type(dict_data[path][\"ja_name\"])==str:\n",
    "                    path_taxon_rank_name.append(dict_data[path][\"taxon_rank_name\"])\n",
    "                else:\n",
    "                    path_taxon_rank_name.append(\"\")\n",
    "            else:\n",
    "                ja_path_name.append(path)\n",
    "                path_taxon_rank_name.append(\"Unknown\")\n",
    "\n",
    "        d[\"path\"] = \"/\".join(path_list)\n",
    "        d[\"ja_path_name\"] = \"/\".join(ja_path_name)\n",
    "        d[\"en_path_name\"] = \"/\".join(en_path_name)\n",
    "        d[\"path_taxon_rank_name\"] = \"/\".join(path_taxon_rank_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Q23809240',\n",
       "  'en_name': 'Dipnotetrapodomorpha',\n",
       "  'ja_name': None,\n",
       "  'en_aliases': {},\n",
       "  'ja_aliases': {},\n",
       "  'img_urls': {0: 'https://www.wikidata.org/wiki/Q23809240#/media/File:Dipnotetrapodomorpha.jpg'},\n",
       "  'taxon_rank': None,\n",
       "  'taxon_name': 'Dipnotetrapodomorpha',\n",
       "  'parent_taxon': 'Q160830',\n",
       "  'path': \"'/Q160830/Q23809240'\"},\n",
       " {'id': 'Q52762328',\n",
       "  'en_name': 'Maniraptoromorpha',\n",
       "  'ja_name': 'マニラプトル形類',\n",
       "  'en_aliases': {},\n",
       "  'ja_aliases': {},\n",
       "  'img_urls': {0: 'https://www.wikidata.org/wiki/Q52762328#/media/File:Ornitholestes%20Royal%20Tyrrell%202.jpg'},\n",
       "  'taxon_rank': None,\n",
       "  'taxon_name': 'Maniraptoromorpha',\n",
       "  'parent_taxon': 'Q2043179',\n",
       "  'path': \"'/Q2043179/Q52762328'\"},\n",
       " {'id': 'Q1209254',\n",
       "  'en_name': 'Tetrapodomorpha',\n",
       "  'ja_name': None,\n",
       "  'en_aliases': {0: 'Tetrapodomorph'},\n",
       "  'ja_aliases': {},\n",
       "  'img_urls': {0: 'https://www.wikidata.org/wiki/Q1209254#/media/File:Tiktaalik%20roseae%20(3705198718).jpg'},\n",
       "  'taxon_rank': None,\n",
       "  'taxon_name': 'Tetrapodomorpha',\n",
       "  'parent_taxon': 'Q23809240',\n",
       "  'path': \"'/Q160830/Q23809240/Q1209254'\"}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedname_list = ['id','en_name','ja_name','en_aliases','ja_aliases','img_urls','taxon_name','taxon_rank','taxon_rank_name','taxon_rank_ja_name','parent_taxon','parent_taxon_name','parent_taxon_ja_name',\"path\",\"ja_path_name\",\"en_path_name\",\"path_taxon_rank_name\"]\n",
    "import csv\n",
    "# with open('data_extract/ontology_path_v2.tsv','w',encoding='utf-8') as csvfile:\n",
    "# with open('data_extract/ontology_path_v3.tsv','w',encoding='utf-8') as csvfile:\n",
    "# with open('data_extract/ontology_path_v4.tsv','w',encoding='utf-8') as csvfile:\n",
    "# with open('data_extract/ontology_path_v5.tsv','w',encoding='utf-8') as csvfile:\n",
    "with open('data_extract/ontology_path_v6.tsv','w',encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = filedname_list,delimiter = \"\\t\")\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "    \n",
    "# with open(\"data_extract/ontology_path_v2.pickle\", 'wb') as f:\n",
    "# with open(\"data_extract/ontology_path_v3.pickle\", 'wb') as f:\n",
    "# with open(\"data_extract/ontology_path_v4.pickle\", 'wb') as f:\n",
    "# with open(\"data_extract/ontology_path_v5.pickle\", 'wb') as f:\n",
    "with open(\"data_extract/ontology_path_v6.pickle\", 'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
