{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pickleからpath加工前の辞書を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_d = dict()\n",
    "for d in data:\n",
    "    ontology_d[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワーク作成　（&親子tsv作成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# child_parent_data = []\n",
    "# for d in data:\n",
    "#     child_parent_data.append({\"id\":d[\"id\"],\"parent_taxon\":d[\"parent_taxon\"]})\n",
    "\n",
    "# import csv\n",
    "# with open('data_extract/child_parent.tsv','w',encoding='utf-8') as csvfile:\n",
    "#     writer = csv.DictWriter(csvfile, fieldnames = [\"id\",\"parent_taxon\"],delimiter = \"\\t\")\n",
    "#     writer.writeheader()\n",
    "#     writer.writerows(child_parent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# G = nx.DiGraph() #無向グラフを作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in child_parent_data:\n",
    "#     G.add_edge(d[\"parent_taxon\"],d[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# nx.draw(G, with_labels = True)\n",
    "# plt.show()\n",
    "\n",
    "#描画試みの結果\n",
    "# ・データが大きすぎるため私の個人PCでは不可能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# パスデータの抜け確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 言語によるパスおよびそのランク表現を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = {}\n",
    "for d in data:\n",
    "    dict_data[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in data:\n",
    "#     if \"path_name\" in d:\n",
    "#         pass\n",
    "#     else:\n",
    "#         path_list = d[\"path\"].replace(\"'\",\"\")\n",
    "#         d[\"path_name\"] = conversion.do(d[\"ja_name\"])\n",
    "#         print('\\r%s                                            ' %(d[\"romaji_name\"]), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:46189]#only bird family\n",
    "# 種や上目といったカテゴリ名もいれてしまってるが誤作動の元なので一旦はずす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    try:\n",
    "        path_list = d[\"path\"].replace(\"'/\",\"\").replace(\"'\",\"\").split(\"/\")\n",
    "        path_list\n",
    "\n",
    "        ja_path_name = []\n",
    "        en_path_name = []\n",
    "        path_taxon_rank_name = []\n",
    "\n",
    "        for path in path_list:\n",
    "            if path in dict_data:\n",
    "                if dict_data[path][\"ja_name\"] != \"\" and type(dict_data[path][\"ja_name\"])==str:\n",
    "                    ja_path_name.append(dict_data[path][\"ja_name\"])\n",
    "                    en_path_name.append(dict_data[path][\"en_name\"])\n",
    "                else:\n",
    "                    ja_path_name.append(dict_data[path][\"en_name\"])\n",
    "                    en_path_name.append(dict_data[path][\"en_name\"])\n",
    "                if dict_data[path][\"taxon_rank_name\"] != \"\" and type(dict_data[path][\"ja_name\"])==str:\n",
    "                    path_taxon_rank_name.append(dict_data[path][\"taxon_rank_name\"])\n",
    "                else:\n",
    "                    path_taxon_rank_name.append(\"\")\n",
    "            else:\n",
    "                ja_path_name.append(path)\n",
    "                path_taxon_rank_name.append(\"Unknown\")\n",
    "\n",
    "        d[\"path\"] = \"/\".join(path_list)\n",
    "        d[\"ja_path_name\"] = \"/\".join(ja_path_name)\n",
    "        d[\"en_path_name\"] = \"/\".join(en_path_name)\n",
    "        d[\"path_taxon_rank_name\"] = \"/\".join(path_taxon_rank_name)\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedname_list = ['id','en_name','ja_name','en_aliases','ja_aliases','img_urls','taxon_name','taxon_rank','taxon_rank_name','taxon_rank_ja_name','parent_taxon','parent_taxon_name','parent_taxon_ja_name',\"path\",\"ja_path_name\",\"en_path_name\",\"path_taxon_rank_name\"]\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data_extract/ontology_path.tsv','w',encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames = filedname_list,delimiter = \"\\t\")\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "    \n",
    "with open(\"data_extract/ontology_path.pickle\", 'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### パスのランク種をtxtに集計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_set = set()\n",
    "# for d in data:\n",
    "#     path_set.add(d[\"path_taxon_rank_name\"])\n",
    "    \n",
    "# path_list = list(path_set)\n",
    "# path_list.sort()\n",
    "\n",
    "# with open('data_extract/path_category.txt', 'w') as f:\n",
    "#     for row in path_list:\n",
    "#         f.write(row)\n",
    "#         f.write(\"\\n\")\n",
    "\n",
    "# #完全な場合のパス\n",
    "# complete_path = [\"subclass\",\"infraclass\",\"superorder\",\"order\",\"suborder\",\"infraorder\",\"superfamily\",\"family\",\"subfamily\",\"tribe\",\"genus\",\"subgenus\",\"species\",\"subspecies\",\"form\"]\n",
    "\n",
    "# # 完全版パスを人手で復元\n",
    "# # すべて人力で修正していくと持たないので，泣き声データにあるもののみ人手で修正することに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模範"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
