{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WikiDataより，Bird（ID：Q5117）を直接的または間接的に親に持つ記事のURLを取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・data_external/query.tsvがURL一覧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_external/query.tsv\") as f:\n",
    "    url_list = f.readlines()[1:]\n",
    "with open('sh1_makejson.sh', 'w', encoding='UTF-8') as f:\n",
    "    f.write(\"#!/bin/bash\\n\")\n",
    "    \n",
    "    for url in url_list:\n",
    "        ID = url.replace(\"http://www.wikidata.org/entity/\",\"\")\n",
    "        command = \"curl -sLH 'Accept: application/json' \"+url+\" | jq . > data_json/\"+ID+\".json\"\n",
    "        f.write(command+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sh1_makejson.shを実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・コマンドラインにて\n",
    "##### ・これが回り終えるまでに3日かかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行結果を順に複数のdata_extract/data_json_n.pickle(ただしn = 1,2,...,7,8)ファイルに保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・data_json/以下のデータがある程度たまったらdata_json_n/に移動する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def logmaker(file_dir,file,error):\n",
    "    with open(file_dir+\"/\"+file+\"_log.txt\", 'w',encoding=\"utf-8\") as log_f:\n",
    "        log_f.write(error+\"\\n\")\n",
    "\n",
    "def Make_jsonpikle(file_dir):\n",
    "    files = os.listdir(file_dir)\n",
    "    files_1 = [file.replace(\".json\",\"\") for file in files]\n",
    "    all_bird_dict = []\n",
    "\n",
    "    for i in range(len(files_1)):\n",
    "        file = files_1[i]\n",
    "        print('\\r%d / %d' %(i, len(files_1)), end='')\n",
    "        try:\n",
    "            with open(file_dir+'/'+file+\".json\", 'r',encoding=\"utf-8\") as rf:\n",
    "                json_dict = json.load(rf)\n",
    "        except:\n",
    "            logmaker(file_dir,file,\"read json\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        bird_dict = {}\n",
    "        url = \"https://www.wikidata.org/wiki/\"+file\n",
    "        bird_dict[\"id\"] = file\n",
    "        try:\n",
    "            bird_dict[\"en_name\"] = json_dict['entities'][file][\"labels\"][\"en\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"en_name\"] = None\n",
    "            logmaker(file_dir,file,\"en_name\")\n",
    "        try:\n",
    "            bird_dict[\"ja_name\"] = json_dict['entities'][file][\"labels\"][\"ja\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"ja_name\"] = None\n",
    "\n",
    "        bird_dict[\"en_aliases\"] = {}\n",
    "        cnt1 = 0\n",
    "        try:\n",
    "            for d in json_dict['entities'][file][\"aliases\"][\"en\"]:\n",
    "                bird_dict[\"en_aliases\"][cnt1] = d[\"value\"]\n",
    "                cnt1 = cnt1 + 1\n",
    "        except:\n",
    "            pass\n",
    "        bird_dict[\"ja_aliases\"] = {}\n",
    "        cnt2 = 0\n",
    "        try:\n",
    "            for d in json_dict['entities'][file][\"aliases\"][\"ja\"]:\n",
    "                bird_dict[\"ja_aliases\"][cnt2]=d[\"value\"]\n",
    "                cnt2 = cnt2 + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        bird_dict[\"img_urls\"] = {}\n",
    "        cnt3 = 0\n",
    "        try:\n",
    "            for img in json_dict['entities'][file][\"claims\"][\"P18\"]:\n",
    "                img_url = url+\"#/media/File:\"+img[\"mainsnak\"][\"datavalue\"][\"value\"].replace(\" \",\"%20\")\n",
    "                bird_dict[\"img_urls\"][cnt3]=img_url\n",
    "                cnt3 = cnt3 + 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"taxon_rank\"] = json_dict['entities'][file][\"claims\"][\"P105\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "        except:\n",
    "            bird_dict[\"taxon_rank\"] = None\n",
    "            logmaker(file_dir,file,\"taxon_rank\")\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"taxon_name\"] = json_dict['entities'][file][\"claims\"][\"P225\"][0][\"mainsnak\"][\"datavalue\"][\"value\"]\n",
    "        except:\n",
    "            bird_dict[\"taxon_name\"] = None\n",
    "            logmaker(file_dir,file,\"taxon_name\")\n",
    "\n",
    "        try:\n",
    "            bird_dict[\"parent_taxon\"] = json_dict['entities'][file][\"claims\"][\"P171\"][0][\"mainsnak\"][\"datavalue\"][\"value\"][\"id\"]\n",
    "        except:\n",
    "            bird_dict[\"parent_taxon\"] = None\n",
    "            logmaker(file_dir,file,\"parent_taxon\")\n",
    "        all_bird_dict.append(bird_dict)\n",
    "\n",
    "\n",
    "    with open(\"data_extract/data_json/\"+file_dir+\".pickle\", 'wb') as bf:\n",
    "        pickle.dump(all_bird_dict,bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6,7,8]:\n",
    "    Make_jsonpikle(\"data_json/data_json_\"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・この時点でdata_json_n(n=1)の各ディレクトリは不要なのでtrushへ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全てのdata_json_n.pickleを結合し，data_extract/ontrogy.pickleを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = []\n",
    "for i in [1,2,3,4,5,6,7,8]:\n",
    "    with open(\"data_extract/data_json/data_json_\"+str(i)+\".pickle\",\"rb\") as f:\n",
    "        data_n = pickle.load(f)\n",
    "        data = data+data_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ontorogyにおけるparent_taxon一覧を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・以下の工程を7回目まで，またはnodataの要素がQ5117のみになるまで継続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents= set([d[\"parent_taxon\"] for d in data])#全てのid\n",
    "ids = set([d[\"id\"] for d in data])#全てのid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・dataのうち，既に記事取得済みのidに存在しないものをnodataに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodata = parents-ids\n",
    "len(nodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1209254', 'Q134143'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodata.remove(None)\n",
    "nodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sh2_add_json.sh', 'w', encoding='UTF-8') as f:\n",
    "    for item in nodata:\n",
    "        i = str(item)\n",
    "        command = \"curl -sLH 'Accept: application/json' http://www.wikidata.org/entity/\"+i+\" | jq . > data_json_add/\"+i+\".json\"\n",
    "        f.write(command+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash sh2_add_json.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 / 10"
     ]
    }
   ],
   "source": [
    "Make_jsonpikle(\"data_json_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,2,3,4,5,6,7,8,\"add\"]:\n",
    "    with open(\"data_extract/data_json/data_json_\"+str(i)+\".pickle\",\"rb\") as f:\n",
    "        data_n = pickle.load(f)\n",
    "        data = data+data_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ・整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整形に必要なデータ\n",
    "data_d = {}\n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d\n",
    "\n",
    "ID_list = []\n",
    "for v in data:\n",
    "    ID_list.append(v[\"taxon_rank\"])\n",
    "    ID_list.append(v[\"parent_taxon\"])\n",
    "ID_set = set(ID_list)\n",
    "\n",
    "ID_d = dict()\n",
    "nodata_set = set()\n",
    "for k in ID_set:\n",
    "    if k in data_d:\n",
    "        ID_d[k] = data_d[k][\"en_name\"]\n",
    "    else:\n",
    "        nodata_set.add(k)\n",
    "        \n",
    "ID_d_ja = dict()\n",
    "nodata_set_ja = set()\n",
    "for k in ID_set:\n",
    "    if k in data_d:\n",
    "        ID_d_ja[k] = data_d[k][\"ja_name\"]\n",
    "    else:\n",
    "        nodata_set_ja.add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整形\n",
    "non_data = []\n",
    "for d in data:\n",
    "    try:\n",
    "        d[\"taxon_rank_name\"] = ID_d[d[\"taxon_rank\"]]\n",
    "        d[\"taxon_rank_ja_name\"] = ID_d_ja[d[\"taxon_rank\"]]\n",
    "\n",
    "        d[\"parent_taxon_name\"] = ID_d[d[\"parent_taxon\"]]\n",
    "        d[\"parent_taxon_ja_name\"] = ID_d_ja[d[\"parent_taxon\"]]\n",
    "\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"en_aliases\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \",\" +v\n",
    "        d[\"en_aliases\"] = s\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"ja_aliases\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \",\" +v\n",
    "        d[\"ja_aliases\"] = s\n",
    "\n",
    "        s = \"\"\n",
    "        for k,v in d[\"img_urls\"].items():\n",
    "            if s == \"\":\n",
    "                s = s + v\n",
    "            else:\n",
    "                s = s + \" \" +v\n",
    "        d[\"img_urls\"] = s\n",
    "    except:\n",
    "        non_data.append(d[\"taxon_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "unique_data = list(map(json.loads, set(map(json.dumps, data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_extract/ontology.pickle\", 'wb') as bf:\n",
    "    pickle.dump(unique_data,bf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ontorogyからidとparentを取得し親子関係を表すtsvであるedges.tsvに格納"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for d in data:\n",
    "    edges.append([d[\"id\"],d[\"parent_taxon\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_extract/edged.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"id\",\"parent_taxon\"])\n",
    "    writer.writerows(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_external/BirdJPBookDB__data.tsvを読込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_external/BirdJPBookDB__data.tsv',encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdJPBookDB_data = [row[0].split(\"\\t\") for row in reader]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## titleからbird_nameを取得し追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdJPBookDB_data_birdname = []\n",
    "for l in BirdJPBookDB_data[1:]:\n",
    "    BirdJPBookDB_data_birdname.append([l[0],l[3].split(\" \")[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BirdJPBookDB__data.tsvのbird_nameとontrogy.pickleのja_nameを結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdJPBookDB__data_2 = []\n",
    "temp_has_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mp3_filemname,birdname_kana in BirdJPBookDB_data_birdname:\n",
    "    for d in data: \n",
    "        if birdname_kana == d[\"ja_name\"] or birdname_kana in d[\"ja_aliases\"].values():\n",
    "            BirdJPBookDB__data_2.append([mp3_filemname,birdname_kana,d[\"id\"]])\n",
    "            temp_has_data.append(birdname_kana)\n",
    "# set(temp_has_data)-set(BirdJPBookDB_data_birdname) = set() より全てのペアを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BirdJPBookDB__data_2.tsvに結果を保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_extract/BirdJPBookDB__data_2.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"audio_id\",\"BirdJPBookDB__data_birdname\",\"id\"])\n",
    "    writer.writerows(BirdJPBookDB__data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_external/BirdResearchDB_label01_32k.tsvを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_external/BirdResearchDB_label01_32k.tsv',encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdResearchDB_data = [row[0].split(\"\\t\") for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enaga  =>  エナガジマロハラロガシラキナガセキレイブリショウクイ"
     ]
    }
   ],
   "source": [
    "import jaconv\n",
    "\n",
    "BirdResearchDB_data_birdname = []\n",
    "\n",
    "for l in BirdResearchDB_data:\n",
    "    new_l = []\n",
    "    mp3_filemname = l[0]\n",
    "    birdname_kana = jaconv.alphabet2kata(l[1])\n",
    "    BirdResearchDB_data_birdname.append([mp3_filemname,birdname_kana])\n",
    "    print('\\r%s  =>  %s' %(l[1],birdname_kana), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdResearchDB_label01_32k_2 = []\n",
    "\n",
    "for mp3_filemname,birdname_kana in BirdResearchDB_data_birdname:\n",
    "    for d in data: \n",
    "        if birdname_kana == d[\"ja_name\"] or birdname_kana in d[\"ja_aliases\"].values():\n",
    "            BirdResearchDB_label01_32k_2.append([mp3_filemname,birdname_kana,d[\"id\"]])#BirdResearchDB_label01_32k_2は確保済みデータ有の音声ファイル名リスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdResearchDB_filename_only = [l[0] for l in BirdResearchDB_data]\n",
    "BirdResearchDB_label01_32k_2_filename_only = [l[0] for l in BirdResearchDB_label01_32k_2]\n",
    "no_data = set(BirdResearchDB_filename_only)-set(BirdResearchDB_label01_32k_2_filename_only)#データの無いものが81件出現\n",
    "\n",
    "no_data_list = []\n",
    "for l in BirdResearchDB_data_birdname:\n",
    "    if l[0] in no_data:\n",
    "        no_data_list.append(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・手動で作成したBirdResearchDB_animal.tsvとBirdResearchDB_handmade.tsvを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_name = {\"エゾリス\",\"アマガエル\",\"ヒキガエル\",\"ヒナコモリ\",\"カモシカ\",\"キタキツネ\",\"モリアオガエル\",\"ネズミ\",\"サル\",\"シカ\",\"タゴガエル\",\"ヤマアカガエル\",\"カジカガエル\",\"コモリ\"}\n",
    "\n",
    "new_no_data_list = []\n",
    "for l in no_data_list:\n",
    "    if l[1] not in animal_name:\n",
    "        new_no_data_list.append(l)\n",
    "        \n",
    "no_data_list = new_no_data_list#88件まで減少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data = [l[1] for l in no_data_list]\n",
    "no_data = set(no_data) # 重複をなくした場合67まで現象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "handmade = []\n",
    "with open('data_extract/BirdResearchDB_handmade.tsv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    handmade = [row[0].split(\"\\t\") for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_list(seq):\n",
    "    seen = []\n",
    "    return [x for x in seq if x not in seen and not seen.append(x)]\n",
    "handmade = get_unique_list([[l[2],jaconv.alphabet2kata(l[3]),l[5]] for l in handmade[1:]])\n",
    "handmade_name_set = set([l[1] for l in handmade])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "handmade_cover_set = handmade_name_set - no_data\n",
    "handmade_cover_list = []\n",
    "\n",
    "for l in handmade:\n",
    "    if l[1] in handmade_cover_set:\n",
    "        handmade_cover_list.append(l)#確保済みデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_no_data_list = []\n",
    "for l in no_data_list:\n",
    "    if l[1] not in handmade_name_set:\n",
    "        new_no_data_list.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata_name_set = set([l[1] for l in new_no_data_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'アムルムッイクイ', 'オサハシブト', 'オチュ', 'キマユ', 'コリガモ', 'ッツバメ', 'ナベズル', 'マナズル', 'マミタヒ'}"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodata_name_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_set = {\n",
    "\"アムルムッイクイ\":\"Q106912069\",\n",
    "\"オサハシブト\":\"Q111674\",\n",
    "\"コリガモ\":\"Q26597\",\n",
    "\"ッツバメ\":\"Q25429\",\n",
    "\"ナベズル\":\"Q494983\",\n",
    "\"マナズル\":\"Q27452479\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_data_list = []\n",
    "for l in no_data_list:\n",
    "    if l[1] in no_data_set:\n",
    "        last_data_list.append(l+[no_data_set[l[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdResearchDB_label01_32k_2_final = BirdResearchDB_label01_32k_2+handmade_cover_list+last_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_extract/BirdResearchDB_label01_32k_2.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"audio_id\",\"BirdJPBookDB__data_birdname\",\"id\"])\n",
    "    writer.writerows(BirdResearchDB_label01_32k_2_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BirdJPBookDB__data_2.tsvおよびBirdResearchDB_label01_32k_2.tsv内のidをもつレコードをontorogyから取得しそのid,parent_taxonをBirdDBedgeに追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_extract/BirdJPBookDB__data_2.tsv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdJPBookDB__data_2 = [row[0].split(\"\\t\") for row in reader] #=>['1_02', 'カイツブリ', 'Q25421']\n",
    "    \n",
    "with open('data_extract/BirdResearchDB_label01_32k_2.tsv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdResearchDB_label01_32k_2 = [row[0].split(\"\\t\") for row in reader]#=>['data01/...0002.wav', 'クマゲラ', 'Q143284']\n",
    "\n",
    "# all_data = BirdJPBookDB__data_2+BirdResearchDB_label01_32k_2[1:]\n",
    "id1 = [l[-1] for l in BirdJPBookDB__data_2]#登場種類数416\n",
    "id2 = [l[-1] for l in BirdResearchDB_label01_32k_2]#登場種類数236\n",
    "ids = set(id1+id2) #音声一覧2件に出て来るid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data_d = {}    \n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdDBedge = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finish = set()#426\n",
    "parents = set()#228\n",
    "error = set()\n",
    "for the_id in ids:\n",
    "    try:\n",
    "        parent_taxon = data_d[the_id][\"parent_taxon\"]\n",
    "        BirdDBedge.append([the_id,parent_taxon])\n",
    "        parents.add(parent_taxon)\n",
    "        finish.add(the_id)\n",
    "    except:\n",
    "        error.add(the_id)\n",
    "        \n",
    "not_member_parent = parents-finish\n",
    "len(not_member_parent)#225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繰り返し\n",
    "for the_id in not_member_parent:\n",
    "    try:\n",
    "        parent_taxon = data_d[the_id][\"parent_taxon\"]\n",
    "        BirdDBedge.append([the_id,parent_taxon])\n",
    "        parents.add(parent_taxon)\n",
    "        finish.add(the_id)\n",
    "    except:\n",
    "        error.add(the_id)\n",
    "        \n",
    "not_member_parent = parents-finish\n",
    "len(not_member_parent)#98 => 33 => 21 => 11 => 5 => 2 => 1\n",
    "# ここで残った一つはTetrapodomorpha:四肢動物門 (Q1209254)で，Birdの子株ではない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_graph/BirdDBedge.tsv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"id\",\"parent_id\"])\n",
    "    writer.writerows(BirdDBedge)\n",
    "# 作成後，手動でQ1209254を含む列を削除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BirdDBnodeの作成（フローチャート要編集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_extract/BirdJPBookDB__data_2.tsv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdJPBookDB__data_2 = [row[0].split(\"\\t\") for row in reader] #=>['1_02', 'カイツブリ', 'Q25421']\n",
    "    \n",
    "with open('data_extract/BirdResearchDB_label01_32k_2.tsv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    BirdResearchDB_label01_32k_2 = [row[0].split(\"\\t\") for row in reader]#=>['data01/...0002.wav', 'クマゲラ', 'Q143284']\n",
    "\n",
    "# all_data = BirdJPBookDB__data_2+BirdResearchDB_label01_32k_2[1:]\n",
    "id1 = [l[-1] for l in BirdJPBookDB__data_2]\n",
    "id2 = [l[-1] for l in BirdResearchDB_label01_32k_2]\n",
    "ids = set(id1+id2) #音声一覧2件に出て来るid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdJPBookDB__data_2_d = dict()\n",
    "for l in BirdJPBookDB__data_2[1:]:\n",
    "    BirdJPBookDB__data_2_d[l[2]] = l[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdResearchDB_label01_32k_2_d = dict()\n",
    "for l in BirdResearchDB_label01_32k_2[1:]:\n",
    "    BirdResearchDB_label01_32k_2_d[l[2]] = l[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "BirdDBnode = []\n",
    "for the_id in finish:\n",
    "    new_list = list(data_d[the_id].values())\n",
    "    JP = 0\n",
    "    if the_id in BirdJPBookDB__data_2_d.keys():\n",
    "        new_list =new_list+BirdJPBookDB__data_2_d[the_id]\n",
    "        JP = 1\n",
    "    else:\n",
    "        new_list =new_list+[\"\",\"\"]\n",
    "    \n",
    "    Research = 0\n",
    "    if the_id in BirdResearchDB_label01_32k_2_d.keys():\n",
    "        new_list = new_list+BirdResearchDB_label01_32k_2_d[the_id]\n",
    "        Research = 1\n",
    "    else:\n",
    "        new_list = new_list+[\"\",\"\"]\n",
    "        \n",
    "    new_list.append(JP)\n",
    "    new_list.append(Research)\n",
    "        \n",
    "    BirdDBnode.append(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_graph/BirdDBnode.tsv', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"id\",\"en_name\",\"ja_name\",\"en_aliases\",\"ja_aliases\",\"img_urls\",\"taxon_rank\",\"taxon_name\",\"parent_taxon\",\"BirdJPBookDB__data_audio_id\",\"BirdJPBookDB__data_birdname\",\"BirdResearchDB_label01_32k_audio_id\",\"BirdResearchDB_label01_32k_birdname\",\"JP\",\"Research\"])\n",
    "    writer.writerows(BirdDBnode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NodeとEdgeの作成=>可視化（音声につながるもののみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_graph/BirdDBedge.tsv\") as f:\n",
    "    BirdDBedge = [s.replace(\"\\n\",\"\").split(\"\\t\") for s in f.readlines()]\n",
    "    BirdDBedge = BirdDBedge[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_graph/BirdDBnode.tsv\",encoding=\"utf-8\") as f:\n",
    "    BirdNode = [s.replace(\"\\n\",\"\").split(\"\\t\") for s in f.readlines()]\n",
    "    BirdNode = BirdNode[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "G = Network(directed=True)\n",
    "for item in BirdDBnode:\n",
    "    c = \"\"\n",
    "    if item[-2:] == [1,0]:\n",
    "        c = \"red\"\n",
    "    if item[-2:] == [1,1]:\n",
    "            c = \"purple\"\n",
    "    if item[-2:] == [0,1]:\n",
    "        c = \"blue\"\n",
    "    if item[-2:] == [0,0]:\n",
    "        c = \"gray\"\n",
    "        \n",
    "    n = \"\"\n",
    "    if item[2] != None:\n",
    "        n = item[2]\n",
    "    elif item[1] != None:\n",
    "        n = item[1]\n",
    "    else:\n",
    "        n = item[0]\n",
    "    G.add_node(item[0], color=c, label=n)\n",
    "    \n",
    "for item in BirdDBedge:\n",
    "    G.add_edge(item[0],item[1],color=\"black\")# 1 → 2 → 3 → 4 → 5\n",
    "\n",
    "G.show(\"data_graph/G.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NodeとEdgeの作成（全てのデータについて）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ノードを整備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_graph/BirdDBedge.tsv\") as f:\n",
    "    BirdDBedge = [s.replace(\"\\n\",\"\").split(\"\\t\") for s in f.readlines()]\n",
    "    BirdDBedge = BirdDBedge[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_graph/BirdDBnode.tsv\",encoding=\"utf-8\") as f:\n",
    "    BirdNode = [s.replace(\"\\n\",\"\").split(\"\\t\") for s in f.readlines()]\n",
    "    BirdNode = BirdNode[1:]\n",
    "\n",
    "BirdNode_d = {}\n",
    "for l in BirdNode:\n",
    "    BirdNode_d[l[0]] = l[1:]\n",
    "# ['Red Phalarope',\n",
    "#  'ハイイロヒレアシシギ',\n",
    "#  \"{'0': 'Red Phalarope', '1': 'Grey Phalarope'}\",\n",
    "#  '{}',\n",
    "#  \"{'0': 'https://www.wikidata.org/wiki/Q208335#/media/File:Phalaropus%20fulicarius%2010.jpg', '1': 'https://www.wikidata.org/wiki/Q208335#/media/File:Grey%20Phalarope.jpg'}\",\n",
    "#  'Q7432',\n",
    "#  'Phalaropus fulicarius',\n",
    "#  'Q253776',\n",
    "#  '2_72',\n",
    "#  'ハイイロヒレアシシギ',\n",
    "#  '',\n",
    "#  '',\n",
    "#  '1',\n",
    "#  '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data_d = {}    \n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d\n",
    "# {'id': 'Q27638142',\n",
    "#  'en_name': 'Diglossa albilatera albilatera',\n",
    "#  'ja_name': None,\n",
    "#  'en_aliases': {},\n",
    "#  'ja_aliases': {},\n",
    "#  'img_urls': {},\n",
    "#  'taxon_rank': 'Q68947',\n",
    "#  'taxon_name': 'Diglossa albilatera albilatera',\n",
    "#  'parent_taxon': 'Q536912'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n2s(l):\n",
    "    new_l = []\n",
    "    for i in l:\n",
    "        if i == None:\n",
    "            new_l.append(\"\")\n",
    "        else:\n",
    "            new_l.appemd(str(inp))\n",
    "    return l\n",
    "\n",
    "all_BirdNode_d = BirdNode_d.copy()\n",
    "for k in data_d.keys():\n",
    "    if k not in BirdNode_d:\n",
    "        d = data_d[k]\n",
    "        all_BirdNode_d[k] = [d[\"en_name\"],d[\"ja_name\"],d[\"en_aliases\"],d[\"ja_aliases\"],d[\"img_urls\"],d[\"taxon_rank\"],d[\"taxon_name\"],d[\"parent_taxon\"],\"\",\"\",\"\",\"\",\"0\",\"0\"]\n",
    "        \n",
    "all_BirdNode = []\n",
    "for k in all_BirdNode_d.keys():\n",
    "    all_BirdNode.append([k]+all_BirdNode_d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('data_graph/all_BirdDBnode.tsv', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"id\",\"en_name\",\"ja_name\",\"en_aliases\",\"ja_aliases\",\"img_urls\",\"taxon_rank\",\"taxon_name\",\"parent_taxon\",\"BirdJPBookDB__data_audio_id\",\"BirdJPBookDB__data_birdname\",\"BirdResearchDB_label01_32k_audio_id\",\"BirdResearchDB_label01_32k_birdname\",\"JP\",\"Research\"])\n",
    "    writer.writerows(all_BirdNode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エッジも整備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data_d = {}    \n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_BirDEdge=[]\n",
    "for k in data_d.keys():\n",
    "    if data_d[k][\"parent_taxon\"] != None:\n",
    "        all_BirDEdge.append([k,data_d[k][\"parent_taxon\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_graph/all_BirdDBedge.tsv', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f,delimiter='\\t')\n",
    "    writer.writerow([\"id\",\"parent_taxon\"])\n",
    "    writer.writerows(all_BirDEdge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pykge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node relation Node 状態のtxtファイルが必要らしいので，全データを整頓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(a_list):\n",
    "    half = len(a_list)//10\n",
    "    return a_list[:half], a_list[half:]\n",
    "\n",
    "dev, train = split_list(all_BirDEdge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_graph/all_BirdDBedge_dev.txt', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    for l in dev:\n",
    "        f.write(str(l[0])+\"\t\"+\"is_child_of\"+\"\t\"+str(l[1])+\"\\n\")\n",
    "        \n",
    "with open('data_graph/all_BirdDBedge_train.txt', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    for l in train:\n",
    "        f.write(str(l[0])+\"\t\"+\"is_child_of\"+\"\t\"+str(l[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .delファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#辞書データ\n",
    "import pickle\n",
    "with open(\"data_extract/ontology.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "data_d = {}    \n",
    "for d in data:\n",
    "    data_d[d[\"id\"]]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = {}\n",
    "c = 1\n",
    "for key in data_d.keys():\n",
    "    id_data[c] = key\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kge/data/mydata/entity_ids.del', 'w', newline='',encoding=\"utf-8\") as f:\n",
    "    for k,v in id_data.items():\n",
    "        f.write(str(k)+\"\t\"+str(v)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation_ids.delは手動で作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = {}\n",
    "for k,v in id_data.items():\n",
    "    data_id[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_BirDEdge=[]\n",
    "for k in data_d.keys():\n",
    "    if data_d[k][\"parent_taxon\"] != None:\n",
    "        try:\n",
    "            id_1 = data_id[k]\n",
    "            id_2 = data_id[data_d[k][\"parent_taxon\"]]\n",
    "            all_BirDEdge.append([id_1,id_2])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(a_list):\n",
    "    per = len(a_list)//10\n",
    "    return a_list[:per],a_list[per:per*2],a_list[per*2:]\n",
    "\n",
    "dev,test,train = split_list(all_BirDEdge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5064 5064 40513\n"
     ]
    }
   ],
   "source": [
    "print(len(dev),len(test),len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_del(filename,data):\n",
    "    with open('kge/data/mydata/'+filename+'.del', 'w', newline='',encoding='utf-8') as f:\n",
    "        for l in data:\n",
    "            f.write(str(l[0])+\"\t\"+\"1\"+\"\t\"+str(l[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_del(\"dev\",dev)\n",
    "write_del(\"test\",test)\n",
    "write_del(\"train\",train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "Python 3",
=======
   "display_name": "Python 3 (ipykernel)",
>>>>>>> d3e4de3f82ba940db2f568867ae5a66c68073ffc
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.0"
=======
   "version": "3.9.6"
>>>>>>> d3e4de3f82ba940db2f568867ae5a66c68073ffc
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
